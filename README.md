# ğŸ¥ Healthcare AR Training System

A production-ready WebAR application for healthcare vocational training, featuring real-time hand tracking, computer vision-based skill validation, and AI-powered coaching. Built entirely for mobile browsers with no app installation required.

**Live Demo:** [https://storage.googleapis.com/babz-store/index.html](https://storage.googleapis.com/babz-store/index.html)  
**Backend API:** [https://healthcare-ar-api-78427087119.europe-west1.run.app](https://healthcare-ar-api-78427087119.europe-west1.run.app)

## ğŸ¯ Overview

This system provides interactive, AR-enhanced training for proper hand washing technique using:
- **Real-time hand pose detection** via MediaPipe
- **Computer vision validation** of 7-step hand washing protocol
- **Object detection** (YOLO) for detecting soap, bottles, and PPE
- **Voice feedback** for immediate coaching
- **AI coaching** via OpenRouter/Claude API (optional)
- **Session tracking** and analytics

---

## âœ¨ Features

### Core Features
- âœ… **Browser-based AR** - Works on any phone, no app installation
- âœ… **Real-time hand tracking** - 30 FPS pose detection using MediaPipe
- âœ… **7-step validation** - Automated assessment of hand washing technique
- âœ… **Voice coaching** - Text-to-speech feedback in real-time
- âœ… **Progress tracking** - Visual checklist and scoring system
- âœ… **Minimal UI** - 80% camera view, collapsible controls
- âœ… **Offline-capable** - Works after initial load

### Advanced Features (Optional)
- ğŸ¤– **AI Coaching** - Personalized feedback via Claude API
- ğŸ¯ **Object Detection** - Detects soap, bottles, masks, gloves
- ğŸ“Š **Session Storage** - Cloud-based training records
- ğŸ“ˆ **Analytics Dashboard** - Instructor insights (coming soon)

---

## ğŸš€ Demo

**Live System:** [https://storage.googleapis.com/babz-store/index.html](https://storage.googleapis.com/babz-store/index.html)

**Backend API:** [https://healthcare-ar-api-78427087119.europe-west1.run.app](https://healthcare-ar-api-78427087119.europe-west1.run.app)

### Quick Test
1. Open demo link on your phone
2. Grant camera permission
3. Show your hands to camera
4. Follow on-screen instructions
5. Complete 7-step hand washing protocol

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Student's Phone Browser                                    â”‚
â”‚                                                             â”‚
â”‚  Frontend (HTML/JS)                                         â”‚
â”‚  â”œâ”€â”€ Camera Access (getUserMedia)                          â”‚
â”‚  â”œâ”€â”€ Hand Tracking (MediaPipe WebAssembly)                 â”‚
â”‚  â”œâ”€â”€ AR Overlays (Canvas API)                              â”‚
â”‚  â”œâ”€â”€ Voice Feedback (Web Speech API)                       â”‚
â”‚  â””â”€â”€ Skill Validation (JavaScript)                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ HTTPS
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Cloud Storage (Static Hosting)                      â”‚
â”‚  â”œâ”€â”€ index.html                                             â”‚
â”‚  â”œâ”€â”€ app.js                                                 â”‚
â”‚  â””â”€â”€ config.js                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           â”‚ Optional API Calls
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloud Run Backend (FastAPI)                                â”‚
â”‚  â”œâ”€â”€ YOLOv8 Object Detection                                â”‚
â”‚  â”œâ”€â”€ AI Coaching (OpenRouter)                               â”‚
â”‚  â””â”€â”€ Session Storage                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Prerequisites

### For Users
- Modern smartphone (iPhone 8+, Android with 2GB RAM)
- Safari 15+ (iOS) or Chrome 100+ (Android)
- Internet connection (only for initial load)

### For Developers
- Python 3.11+
- Node.js 18+ (optional, for local testing)
- Google Cloud SDK
- GCP account with billing enabled

---

## ğŸ› ï¸ Installation & Deployment

### Option 1: Deploy Complete System (Recommended)

#### 1. Clone Repository
```bash
git clone https://github.com/YOUR_USERNAME/healthcare-ar-training.git
cd healthcare-ar-training
```

#### 2. Deploy Frontend to Cloud Storage
```bash
# Set your GCP project
gcloud config set project YOUR_PROJECT_ID

# Create bucket
gsutil mb -l europe-west1 gs://YOUR_BUCKET_NAME

# Upload files
gsutil cp index.html app.js config.js gs://YOUR_BUCKET_NAME/

# Make public
gsutil iam ch allUsers:objectViewer gs://YOUR_BUCKET_NAME

# Set cache headers
gsutil setmeta -h "Cache-Control:public, max-age=3600" gs://YOUR_BUCKET_NAME/*.html
gsutil setmeta -h "Cache-Control:public, max-age=31536000" gs://YOUR_BUCKET_NAME/*.js

# Your URL: https://storage.googleapis.com/YOUR_BUCKET_NAME/index.html
```

#### 3. Deploy Backend to Cloud Run (Optional)
```bash
cd backend

# Deploy
gcloud run deploy healthcare-ar-api \
  --source . \
  --region europe-west1 \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 2 \
  --project YOUR_PROJECT_ID

# Make public
gcloud run services add-iam-policy-binding healthcare-ar-api \
  --region=europe-west1 \
  --member=allUsers \
  --role=roles/run.invoker \
  --project YOUR_PROJECT_ID
```

#### 4. Update Config
Edit `config.js`:
```javascript
objectDetection: {
    enabled: true,
    apiEndpoint: 'https://YOUR-API-URL.run.app',
}
```

Upload updated config:
```bash
gsutil cp config.js gs://YOUR_BUCKET_NAME/
```

---

### Option 2: Local Development

#### 1. Install Dependencies
```bash
# Backend
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run backend
python main.py
# Backend runs on http://localhost:8080
```

#### 2. Run Frontend
```bash
cd ..
python3 server.py
# Frontend runs on https://localhost:8443
```

#### 3. Test
Open `https://localhost:8443` in your browser

---

## âš™ï¸ Configuration

### Frontend (`config.js`)

```javascript
const CONFIG = {
    // Hand tracking
    handTracking: {
        maxHands: 2,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
    },
    
    // Object detection (optional)
    objectDetection: {
        enabled: false,  // Set to true when backend is deployed
        apiEndpoint: '',  // Your Cloud Run URL
        targetObjects: ['soap', 'bottle', 'towel', 'mask'],
        confidenceThreshold: 0.5,
        sendFramesPerSecond: 1
    },
    
    // AI coaching (optional)
    aiCoaching: {
        enabled: false,  // Set to true to enable
        apiKey: '',  // Your OpenRouter API key
        model: 'anthropic/claude-3.5-sonnet',
        maxFeedbackPerSession: 5
    },
    
    // Training
    training: {
        stepRequirements: {
            hands_visible: 3,
            wetting_motion: 3,
            soap_application: 5,
            interlace_fingers: 3,
            back_of_hands: 3,
            thumbs: 2,
            rinse_motion: 5
        }
    }
};
```

### Backend (Environment Variables)

Create `backend/.env`:
```bash
PORT=8080
MODEL_PATH=yolov8n.pt
LOG_LEVEL=INFO
```

---

## ğŸ“Š Performance Metrics

### Frontend Performance
- **Load time:** < 3 seconds (3G connection)
- **FPS:** 25-30 (hand tracking)
- **Latency:** < 50ms (pose detection)
- **Bundle size:** 52KB (excluding MediaPipe CDN)

### Backend Performance
- **Object detection:** ~50ms per frame
- **Cold start:** ~3 seconds (Cloud Run)
- **Warm response:** ~100ms
- **Concurrent users:** 1000+ (auto-scaling)

---

## ğŸ§ª Testing

### Manual Testing
```bash
# Test frontend
open https://storage.googleapis.com/YOUR_BUCKET_NAME/index.html

# Test backend health
curl https://YOUR-API-URL.run.app/health

# Test object detection
curl -X POST -F "image=@test.jpg" https://YOUR-API-URL.run.app/detect
```

### Browser Console
1. Open app on phone
2. Open DevTools (Desktop: F12, Mobile: Safari > Develop)
3. Check Console for errors
4. Verify hand tracking FPS
5. Test object detection logs

### Load Testing
```bash
# Backend load test
ab -n 1000 -c 10 https://YOUR-API-URL.run.app/health
```

---

## ğŸ“± Browser Compatibility

| Browser | Version | Status |
|---------|---------|--------|
| Safari (iOS) | 15+ | âœ… Full support |
| Chrome (Android) | 100+ | âœ… Full support |
| Firefox (Android) | 105+ | âš ï¸ Partial (no WebGL in some devices) |
| Samsung Internet | 18+ | âœ… Full support |
| Edge (Mobile) | 100+ | âœ… Full support |

---

## ğŸ”’ Security

### Frontend
- HTTPS only (required for camera access)
- No sensitive data stored locally
- API keys in config (use proxy in production)

### Backend
- CORS enabled (configure for production)
- Input validation on all endpoints
- Rate limiting (Cloud Run default)
- No authentication (add for production)

### Recommendations for Production
1. **API Proxy:** Hide OpenRouter key server-side
2. **Authentication:** Add user login
3. **Rate Limiting:** Implement per-user limits
4. **HTTPS:** Use custom domain with SSL
5. **CORS:** Restrict to your domains only

---

## ğŸ› Troubleshooting

### Camera Not Working
- **Issue:** HTTPS required for camera access
- **Fix:** Use Cloud Storage URL (already HTTPS)

### Hand Tracking Slow
- **Issue:** Low-end device or poor lighting
- **Fix:** Reduce `maxNumHands` to 1, improve lighting

### Object Detection Failing
- **Issue:** YOLO model not loaded
- **Fix:** Check backend logs, increase memory to 4Gi

### Config Changes Not Reflecting
- **Issue:** Browser cache
- **Fix:** 
```bash
gsutil setmeta -h "Cache-Control:no-cache, max-age=0" gs://BUCKET/config.js
```

---

## ğŸ—ºï¸ Roadmap

### Phase 1 (Current) âœ…
- [x] Hand tracking with MediaPipe
- [x] 7-step validation
- [x] Voice feedback
- [x] Cloud deployment
- [x] Object detection backend

### Phase 2 (Next)
- [ ] Multi-language support
- [ ] Instructor dashboard
- [ ] Session replay
- [ ] Progress analytics
- [ ] Custom training scenarios

### Phase 3 (Future)
- [ ] Multi-user sessions
- [ ] Live instructor feedback
- [ ] VR headset support
- [ ] Advanced AI coaching
- [ ] Gamification features

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

### Development Guidelines
- Follow existing code style
- Add tests for new features
- Update documentation
- Test on multiple devices

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘ Acknowledgments

### Technologies Used
- [MediaPipe](https://mediapipe.dev/) - Hand tracking
- [YOLOv8](https://github.com/ultralytics/ultralytics) - Object detection
- [FastAPI](https://fastapi.tiangolo.com/) - Backend framework
- [Google Cloud Platform](https://cloud.google.com/) - Hosting & deployment
- [OpenRouter](https://openrouter.ai/) - AI coaching

### Inspiration
This project was developed as a technical assessment to demonstrate:
- Full-stack web development
- Computer vision integration
- Cloud deployment expertise
- Mobile-first design
- Cost-effective solution architecture

---

## ğŸ“ Contact

**Developer:** Abdulkareem  
**Project Repository:** [https://github.com/CodeKage25/healthcare-ar-training](https://github.com/CodeKage25/healthcare-ar-training)  
**Live Demo:** [https://storage.googleapis.com/babz-store/index.html](https://storage.googleapis.com/babz-store/index.html)

---

## ğŸ“ˆ Project Stats

- **Lines of Code:** >1,000
- **Development Time:** Assessment project
- **Deployment Time:** 10 minutes
- **Performance:** 30 FPS hand tracking
- **Scalability:** 1,000+ concurrent users

---

## ğŸ“ Educational Use

This system can be adapted for training in:
- âœ… Hand washing technique
- âœ… PPE donning/doffing
- âœ… Sterile procedures
- âœ… CPR hand placement
- âœ… Injection technique
- âœ… Wound care procedures

**Customization:** Contact for adaptation to specific training scenarios.